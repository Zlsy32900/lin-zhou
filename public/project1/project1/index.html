<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Quadruped Robot Control Optimization via Reinforcement Learning | Lin Zhou&#39;s Homepage</title>
<meta name="keywords" content="">
<meta name="description" content="Summary  This project make use of whole body control scheme combing with DCM indicator and impedance control scheme. It employs reinforcement learning to enhance the selection of gain parameters, ultimately achieving superior performance when compared to traditional and binary impedance control methods. Additionally, it can adaptively select the optimal gain settings based on varying disturbance profiles.   Project Description  Controlling a quadruped robot presents a significant challenge in legged robot applications due to its higher number of Degrees of Freedom (DoFs) and the coupling effects between its connectors that cannot be ignored.">
<meta name="author" content="">
<link rel="canonical" href="https://zlsy32900.github.io/lin-zhou/project1/project1/">
<meta name="google-site-verification" content="XYZabc">
<link crossorigin="anonymous" href="https://zlsy32900.github.io/lin-zhou/assets/css/stylesheet.735c14aef5bd53538764fbe842da3b6b2041059e13045d88f457bc438e58e012.css" integrity="sha256-c1wUrvW9U1OHZPvoQto7ayBBBZ4TBF2I9Fe8Q45Y4BI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="https://zlsy32900.github.io/lin-zhou/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://zlsy32900.github.io/lin-zhou/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://zlsy32900.github.io/lin-zhou/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://zlsy32900.github.io/lin-zhou/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://zlsy32900.github.io/lin-zhou/apple-touch-icon.png">
<link rel="mask-icon" href="https://zlsy32900.github.io/lin-zhou/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123-45', 'auto');
	
	ga('send', 'pageview');
}
</script>
<meta property="og:title" content="Quadruped Robot Control Optimization via Reinforcement Learning" />
<meta property="og:description" content="Summary  This project make use of whole body control scheme combing with DCM indicator and impedance control scheme. It employs reinforcement learning to enhance the selection of gain parameters, ultimately achieving superior performance when compared to traditional and binary impedance control methods. Additionally, it can adaptively select the optimal gain settings based on varying disturbance profiles.   Project Description  Controlling a quadruped robot presents a significant challenge in legged robot applications due to its higher number of Degrees of Freedom (DoFs) and the coupling effects between its connectors that cannot be ignored." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://zlsy32900.github.io/lin-zhou/project1/project1/" /><meta property="article:section" content="project1" />
<meta property="article:published_time" content="2023-10-22T13:50:06+01:00" />
<meta property="article:modified_time" content="2023-10-22T13:50:06+01:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Quadruped Robot Control Optimization via Reinforcement Learning"/>
<meta name="twitter:description" content="Summary  This project make use of whole body control scheme combing with DCM indicator and impedance control scheme. It employs reinforcement learning to enhance the selection of gain parameters, ultimately achieving superior performance when compared to traditional and binary impedance control methods. Additionally, it can adaptively select the optimal gain settings based on varying disturbance profiles.   Project Description  Controlling a quadruped robot presents a significant challenge in legged robot applications due to its higher number of Degrees of Freedom (DoFs) and the coupling effects between its connectors that cannot be ignored."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Quadruped Robot Control Optimization via Reinforcement Learning",
      "item": "https://zlsy32900.github.io/lin-zhou/project1/project1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Quadruped Robot Control Optimization via Reinforcement Learning",
  "name": "Quadruped Robot Control Optimization via Reinforcement Learning",
  "description": "Summary  This project make use of whole body control scheme combing with DCM indicator and impedance control scheme. It employs reinforcement learning to enhance the selection of gain parameters, ultimately achieving superior performance when compared to traditional and binary impedance control methods. Additionally, it can adaptively select the optimal gain settings based on varying disturbance profiles.   Project Description  Controlling a quadruped robot presents a significant challenge in legged robot applications due to its higher number of Degrees of Freedom (DoFs) and the coupling effects between its connectors that cannot be ignored.",
  "keywords": [
    
  ],
  "articleBody": "Summary  This project make use of whole body control scheme combing with DCM indicator and impedance control scheme. It employs reinforcement learning to enhance the selection of gain parameters, ultimately achieving superior performance when compared to traditional and binary impedance control methods. Additionally, it can adaptively select the optimal gain settings based on varying disturbance profiles.   Project Description  Controlling a quadruped robot presents a significant challenge in legged robot applications due to its higher number of Degrees of Freedom (DoFs) and the coupling effects between its connectors that cannot be ignored. Moreover, it is essential for the robot to exhibit compliance and effectively interact with its environment. Therefore, the proposed control scheme is as follows.    However, classical binary gains used in impedance control strategies tend to make the robot overly stiff and incapable of adapting to diverse environments and various disturbances. This occurs because in an impedance control strategy, the damping and stiffness gains have a direct impact on the external forces applied in the robot’s feet. This, in turn, affects the robot’s overall stability. When external disturbances occur, the system should tend to opt for smaller gain values to minimize the external forces acting on the robot’s feet, allowing the robot to maintain contact with the ground for an extended duration. Once stability is restored, it becomes necessary to increase these gains to enhance the precision of task execution. This process cannot be efficiently managed using fixed binary gain settings because the robot cannot be continuously supervised. Consequently, an automated gain adjustment mechanism is necessary.\n  To address this challenge, reinforcement learning is employed. Therefore, this project leverages deep reinforcement learning (DRL), specifically TD3 (Twin Delayed Deep Deterministic Policy Gradients), to tackle this problem.\n   Result After training, the final result could be shown in the following.\nWhen comparing the performance of reinforcement learning (RL) with binary gains, it becomes evident that RL outperforms in both anti-disturbance capability and tracking capability. The red line represents the results achieved using RL, while the lines of other colors correspond to those obtained with binary gains.\n Demos There are two scenarios:\n Firstly, when applying a 5N force to the robot’s base at regular time intervals, it is evident that RL promptly detects and responds to this disturbance by making immediate gain adjustments. Secondly, during random dragging tests where the robot experiences unpredictable and varying disturbances, the robot exhibits the capability to recover swiftly and respond effectively. This adaptability underscores the effectiveness of the RL-based control approach.    ",
  "wordCount" : "412",
  "inLanguage": "en",
  "datePublished": "2023-10-22T13:50:06+01:00",
  "dateModified": "2023-10-22T13:50:06+01:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://zlsy32900.github.io/lin-zhou/project1/project1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lin Zhou's Homepage",
    "logo": {
      "@type": "ImageObject",
      "url": "https://zlsy32900.github.io/lin-zhou/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://zlsy32900.github.io/lin-zhou/" accesskey="h" title="Lin Zhou&#39;s Homepage (Alt + H)">Lin Zhou&#39;s Homepage</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://zlsy32900.github.io/project1/project1" title="Project">
                    <span>Project</span>
                </a>
            </li>
            <li>
                <a href="https://zlsy32900.github.io/cv.pdf" title="CV">
                    <span>CV</span>
                </a>
            </li>
            <li>
                <a href="https://zlsy32900.github.io/introduction" title="Introduction">
                    <span>Introduction</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://zlsy32900.github.io/lin-zhou/">Home</a></div>
    <h1 class="post-title">
      Quadruped Robot Control Optimization via Reinforcement Learning
    </h1>
    <div class="post-meta"><span title='2023-10-22 13:50:06 +0100 BST'>October 22, 2023</span>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#summary" aria-label="Summary">Summary</a></li>
                <li>
                    <a href="#project-description" aria-label="Project Description">Project Description</a></li>
                <li>
                    <a href="#result" aria-label="Result">Result</a></li>
                <li>
                    <a href="#demos" aria-label="Demos">Demos</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h1>
<ul>
<li>This project make use of whole body control scheme combing with DCM indicator and impedance control scheme. It employs reinforcement learning to enhance the selection of gain parameters, ultimately achieving superior performance when compared to traditional and binary impedance control methods. Additionally, it can adaptively select the optimal gain settings based on varying disturbance profiles.</li>
</ul>
<hr>
<h1 id="project-description">Project Description<a hidden class="anchor" aria-hidden="true" href="#project-description">#</a></h1>
<ul>
<li>Controlling a quadruped robot presents a significant challenge in legged robot applications due to its higher number of Degrees of Freedom (DoFs) and the coupling effects between its connectors that cannot be ignored. Moreover, it is essential for the robot to exhibit compliance and effectively interact with its environment. Therefore, the proposed control scheme is as follows.</li>
</ul>
<p><img loading="lazy" src="https://zlsy32900.github.io/lin-zhou/images/control_structure.jpg" alt="Control Structure"  />
</p>
<ul>
<li>
<p>However, classical binary gains used in impedance control strategies tend to make the robot overly stiff and incapable of adapting to diverse environments and various disturbances. This occurs because in an impedance control strategy, the damping and stiffness gains have a direct impact on the external forces applied in the robot&rsquo;s feet. This, in turn, affects the robot&rsquo;s overall stability. When external disturbances occur, the system should tend to opt for smaller gain values to minimize the external forces acting on the robot&rsquo;s feet, allowing the robot to maintain contact with the ground for an extended duration. Once stability is restored, it becomes necessary to increase these gains to enhance the precision of task execution. This process cannot be efficiently managed using fixed binary gain settings because the robot cannot be continuously supervised. Consequently, an automated gain adjustment mechanism is necessary.</p>
</li>
<li>
<p>To address this challenge, reinforcement learning is employed. Therefore, this project leverages deep reinforcement learning (DRL), specifically TD3 (Twin Delayed Deep Deterministic Policy Gradients), to tackle this problem.</p>
</li>
</ul>
<hr>
<h1 id="result">Result<a hidden class="anchor" aria-hidden="true" href="#result">#</a></h1>
<p>After training, the final result could be shown in the following.</p>
<p>When comparing the performance of reinforcement learning (RL) with binary gains, it becomes evident that RL outperforms in both anti-disturbance capability and tracking capability. The red line represents the results achieved using RL, while the lines of other colors correspond to those obtained with binary gains.</p>
<p><img loading="lazy" src="https://zlsy32900.github.io/lin-zhou/gain_comparison_x.png" alt="Comparison with different binary in X dimension"  />

<img loading="lazy" src="https://zlsy32900.github.io/lin-zhou/gain_comparison_y.png" alt="Comparison with different binary in Y dimension"  />

<img loading="lazy" src="https://zlsy32900.github.io/lin-zhou/gain_comparison_z.png" alt="Comparison with different binary in Z dimension"  />
</p>
<hr>
<h1 id="demos">Demos<a hidden class="anchor" aria-hidden="true" href="#demos">#</a></h1>
<p>There are two scenarios:</p>
<ul>
<li>Firstly, when applying a 5N force to the robot&rsquo;s base at regular time intervals, it is evident that RL promptly detects and responds to this disturbance by making immediate gain adjustments.</li>
<li>Secondly, during random dragging tests where the robot experiences unpredictable and varying disturbances, the robot exhibits the capability to recover swiftly and respond effectively. This adaptability underscores the effectiveness of the RL-based control approach.</li>
</ul>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/4grVbI8qVRc" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>



  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://zlsy32900.github.io/lin-zhou/">Lin Zhou&#39;s Homepage</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
